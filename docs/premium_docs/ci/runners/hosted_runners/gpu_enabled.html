<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title># Machine types available for GPU-enabled runners</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <pre><code><hr />
<p>stage: Production Engineering
group: Runners Platform
info: To determine the technical writer assigned to the Stage/Group associated with this page, see https://handbook.gitlab.com/handbook/product/ux/technical-writing/#assignments
title: GPU-enabled hosted runners</p>
<hr />
<p>{{&lt; details &gt;}}</p>
<ul>
<li>Tier: Premium, Ultimate</li>
<li>Offering: GitLab.com</li>
</ul>
<p>{{&lt; /details &gt;}}</p>
<p>GitLab provides GPU-enabled hosted runners to accelerate heavy compute workloads for ModelOps
or HPC such as the training or deployment of Large Language Models (LLMs) as part of ModelOps workloads.</p>
<p>GitLab provides GPU-enabled runners only on Linux. For more information about how these runners work, see <a href="linux.html">Hosted runners on Linux</a></p>
<h2>Machine types available for GPU-enabled runners</h2>
<p>The following machine types are available for GPU-enabled runners on Linux x86-64.</p>
<table>
<thead>
<tr>
<th>Runner Tag</th>
<th>vCPUs</th>
<th>Memory</th>
<th>Storage</th>
<th>GPU</th>
<th>GPU Memory</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>saas-linux-medium-amd64-gpu-standard</code></td>
<td>4</td>
<td>15 GB</td>
<td>50 GB</td>
<td>1 NVIDIA Tesla T4 (or similar)</td>
<td>16 GB</td>
</tr>
</tbody>
</table>
<h2>Container images with GPU drivers</h2>
<p>As with GitLab hosted runners on Linux, your job runs in an isolated virtual machine (VM)
with a bring-your-own-image policy. GitLab mounts the GPU from the host VM into
your isolated environment. To use the GPU, you must use a Docker image with the
GPU driver installed. For NVIDIA GPUs, you can use their <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/cuda">CUDA Toolkit</a>.</p>
<h2>Example <code>.gitlab-ci.yml</code> file</h2>
<p>In the following example of the <code>.gitlab-ci.yml</code> file, the NVIDIA CUDA base Ubuntu image is used.
In the <code>script:</code> section, you install Python.</p>
<pre><code class="language-yaml">gpu-job:
  stage: build
  tags:
    - saas-linux-medium-amd64-gpu-standard
  image: nvcr.io/nvidia/cuda:12.1.1-base-ubuntu22.04
  script:
    - apt-get update
    - apt-get install -y python3.10
    - python3.10 --version
</code></pre>
<p>If you don't want to install larger libraries such as Tensorflow or XGBoost each time you run a job, you can create your own image with all the required components pre-installed.
Watch this demo to learn how to leverage GPU-enabled hosted runners to train an XGBoost model:</p>
<div class="video-fallback">
  Video demonstration of GitLab GPU-enabled hosted runners: <a href="https://youtu.be/tElegG4NCZ0">Train XGboost models with GitLab</a>.
</div>
<figure class="video-container">
  <iframe src="https://www.youtube-nocookie.com/embed/tElegG4NCZ0" frameborder="0" allowfullscreen> </iframe>
</figure></code></pre>
</body>
</html>
